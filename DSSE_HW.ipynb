{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3600b553-152f-4664-bf81-f3744c063a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as mp\n",
    "import time\n",
    "import skimage as ski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169f7076-3e73-4121-b274-75b953c72c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "nanos_to_seconds = 1 / 1e6\n",
    "\n",
    "dete_temp = np.genfromtxt(\n",
    "\t'data_external/detectorTemp.txt', delimiter=','\n",
    "\t)  #import delimited data\n",
    "dete_temp = dete_temp[1:]  #trim off nans created from lable line\n",
    "dete_temp[:, 0] = dete_temp[:,\n",
    "\t\t\t\t  0] * nanos_to_seconds  #convert to seconds right away\n",
    "\n",
    "dist_dopp = np.genfromtxt(\n",
    "\t'data_external/distanceAndDoppler.txt', delimiter=','\n",
    "\t)  #import delimited data\n",
    "dist_dopp = dist_dopp[1:]  #trim off nans created from lable line\n",
    "dist_dopp[:, 0] = dist_dopp[:,\n",
    "\t\t\t\t  0] * nanos_to_seconds  #convert to seconds right away\n",
    "\n",
    "inst_tele = np.genfromtxt(\n",
    "\t'data_external/instrumentTelemetry.txt', delimiter=','\n",
    "\t)  #import delimited data\n",
    "inst_tele = inst_tele[1:]  #trim off nans created from lable line\n",
    "inst_tele[:, 0] = inst_tele[:,\n",
    "\t\t\t\t  0] * nanos_to_seconds  #convert to seconds right away\n",
    "\n",
    "inte_time = np.genfromtxt(\n",
    "\t'data_external/integrationTime.txt', delimiter=','\n",
    "\t)  #import delimited data\n",
    "inte_time = inte_time[1:]  #trim off nans created from lable line\n",
    "inte_time[:, 0] = inte_time[:,\n",
    "\t\t\t\t  0] * nanos_to_seconds  #convert to seconds right away\n",
    "\n",
    "# plans = np.genfromtxt('lasp_dsse_hw/data/plans.txt', delimiter=',') #import delimited data\n",
    "# plans = plan[1:] #trim off nans created from lable line\n",
    "\n",
    "refe_spec = np.genfromtxt(\n",
    "\t'data_external/referenceSpectrum.txt', delimiter=','\n",
    "\t)  #import delimited data\n",
    "refe_spec = refe_spec[1:]  #trim off nans created from lable line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c56c481-b6a7-4cd7-b357-0f9bb52b60b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp.figure(figsize=(10, 5))\n",
    "mp.plot(\n",
    "\trefe_spec[:, 0], refe_spec[:, 1]\n",
    "\t)  #glance at the refernce spectrum to check sanity\n",
    "print(len(refe_spec[:, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d07891-04d4-4894-8493-aff1e2c9ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's find out what's inside the telemetry\n",
    "#planName, startTime, endTime #all in Âµs\n",
    "#DownScan, 9.434134508500002E14, 9.434178731000002E14\n",
    "#Dark, 9.434192873600002E14, 9.434237008000002E14\n",
    "#UpScan, 9.434251237500002E14, 9.434295278700002E14\n",
    "# we are interested in the \"plan\" which starts at 9.434134508500002E14\n",
    "down_start_time = 9.434134508500002e8\n",
    "down_end_time = 9.434178731000002e8\n",
    "print(\"down time seconds: \" + str((down_end_time - down_start_time)))\n",
    "dark_start_time = 9.434192873600002e8\n",
    "dark_end_time = 9.434237008000002e8\n",
    "print(\"dark time seconds: \" + str((dark_end_time - dark_start_time)))\n",
    "up_start_time = 9.434251237500002e8\n",
    "up_end_time = 9.434295278700002e8\n",
    "print(\"up time seconds: \" + str((up_end_time - up_start_time)))\n",
    "\n",
    "data_end_time = 9.434295267500002E14  #instrument telemetry ends at 9.434295267500002E14, which isn't the end of the upscan planned time, so that's a thing to figure out.\n",
    "\n",
    "down_start = np.where(inst_tele[:, 0] >= down_start_time)[0][0]\n",
    "down_end = np.where(inst_tele[:, 0] >= down_end_time)[0][0]\n",
    "print(\"down samples: \" + str(down_end - down_start))\n",
    "dark_start = np.where(inst_tele[:, 0] >= dark_start_time)[0][0]\n",
    "dark_end = np.where(inst_tele[:, 0] >= dark_end_time)[0][0]\n",
    "print(\"dark samples: \" + str(dark_end - dark_start))\n",
    "up_start = np.where(inst_tele[:, 0] >= up_start_time)[0][0]\n",
    "up_end = len(\n",
    "\tinst_tele[:, 0]\n",
    "\t)  #np.where (inst_tele[:,0]==up_end_time)[0][0] #this breaks, looks like the data ends before the plan does.\n",
    "print(\"up samples: \" + str(up_end - up_start))\n",
    "\n",
    "down_raw = inst_tele[down_start:down_end, :]\n",
    "dark_raw = inst_tele[dark_start:dark_end, :]\n",
    "up_raw = inst_tele[up_start:up_end, :]\n",
    "\n",
    "#we got lucky that \"==\" worked, though we could have done \">\" and taken the first element of the output array.\n",
    "\n",
    "# mp.figure(figsize=(9,3))\n",
    "# mp.title('microsecondsSinceGpsEpoch per data point')\n",
    "# mp.plot(inst_tele[down_start:up_end-1,0]-down_start_time,np.diff(inst_tele[down_start:up_end,0]))\n",
    "# mp.show()\n",
    "\n",
    "# mp.figure(2,figsize=(9,3))\n",
    "fig, axs = mp.subplots(3, 1, figsize=(10, 10))\n",
    "axs[0].plot(down_raw[:, 0] - down_raw[0, 0], down_raw[:, 2])\n",
    "axs[0].title.set_text('downscan')\n",
    "axs[1].plot(dark_raw[:, 0] - dark_raw[0, 0], dark_raw[:, 2])\n",
    "axs[1].title.set_text('darks')\n",
    "axs[2].plot(up_raw[:, 0] - up_raw[0, 0], up_raw[:, 2])\n",
    "axs[2].title.set_text('upscan')\n",
    "# fig.show()\n",
    "\n",
    "# mp.figure(2,figsize=(9,3))\n",
    "fig, axs = mp.subplots(3, 1, figsize=(10, 10))\n",
    "axs[0].plot(down_raw[:-1, 0] - down_raw[0, 0], np.diff(down_raw[:, 0]))\n",
    "axs[0].title.set_text('downscan exposure time per sample')\n",
    "axs[1].plot(dark_raw[:-1, 0] - dark_raw[0, 0], np.diff(dark_raw[:, 0]))\n",
    "axs[1].title.set_text('darks exposure time per sample')\n",
    "axs[2].plot(up_raw[:-1, 0] - up_raw[0, 0], np.diff(up_raw[:, 0]))\n",
    "axs[2].title.set_text('upscan exposure time per sample')\n",
    "\n",
    "down_exposure = np.diff(down_raw[:, 0])[0]\n",
    "dark_exposure = np.diff(dark_raw[:, 0])[0]\n",
    "up_exposure = np.diff(up_raw[:, 0])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "down_start_time = 9.434134508500002e8\n",
    "down_end_time = 9.434178731000002e8\n",
    "print(\"down time seconds: \" + str((down_end_time - down_start_time)))\n",
    "dark_start_time = 9.434192873600002e8\n",
    "dark_end_time = 9.434237008000002e8\n",
    "print(\"dark time seconds: \" + str((dark_end_time - dark_start_time)))\n",
    "up_start_time = 9.434251237500002e8\n",
    "up_end_time = 9.434295278700002e8\n",
    "print(\"up time seconds: \" + str((up_end_time - up_start_time)))\n",
    "\n",
    "down_start_temp = np.where(dete_temp[:, 0] >= down_start_time)[0][0]\n",
    "down_end_temp = np.where(dete_temp[:, 0] >= down_end_time)[0][0]\n",
    "print(\"down samples: \" + str(down_end_temp - down_start_temp))\n",
    "dark_start_temp = np.where(dete_temp[:, 0] >= dark_start_time)[0][0]\n",
    "dark_end_temp = np.where(dete_temp[:, 0] >= dark_end_time)[0][0]\n",
    "print(\"dark samples: \" + str(dark_end_temp - dark_start_temp))\n",
    "up_start_temp = np.where(dete_temp[:, 0] >= up_start_time)[0][0]\n",
    "up_end_temp = np.where(dete_temp[:, 0] >= up_end_time)[0][\n",
    "\t0] \n",
    "print(\"up samples: \" + str(up_end_temp - up_start_temp))\n",
    "\n",
    "print(\n",
    "\t'rough estimate of sunlight temp delta: ' + str(\n",
    "\t\tdete_temp[up_end_temp, 1] - dete_temp[up_start_temp, 1]\n",
    "\t\t)\n",
    "\t)\n",
    "\n",
    "down_temp = dete_temp[down_start_temp:down_end_temp, :]\n",
    "dark_temp = dete_temp[dark_start_temp:dark_end_temp, :]\n",
    "up_temp = dete_temp[up_start_temp:up_end_temp, :]\n",
    "\n",
    "mp.figure(figsize=(10, 3))\n",
    "mp.title('temp (C) during exposures')\n",
    "mp.plot(down_temp[:, 0] - down_temp[0, 0], down_temp[:, 1])\n",
    "mp.plot(dark_temp[:, 0] - dark_temp[0, 0], dark_temp[:, 1])\n",
    "mp.plot(up_temp[:, 0] - up_temp[0, 0], up_temp[:, 1])\n",
    "mp.legend(['down exposure', 'darks exposure', 'up exposure'])\n",
    "# mp.plot(dete_temp[162:4604,1])\n",
    "\n",
    "ax = mp.figure(figsize=(10, 3))\n",
    "mp.title('temp (C) overall')\n",
    "mp.plot(dete_temp[:, 0], dete_temp[:, 1])\n",
    "mp.plot(down_temp[:, 0], down_temp[:, 1])\n",
    "mp.plot(dark_temp[:, 0], dark_temp[:, 1])\n",
    "mp.plot(up_temp[:, 0], up_temp[:, 1])\n",
    "mp.legend(\n",
    "\t['all temperature values', 'down exposure', 'darks exposure', 'up exposure']\n",
    "\t)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57a6055117cbaa94"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# #lets try axtracting a curve from temp, to see if we'll be able to use the method for the noisier darks\n",
    "# #this ended up being the wrong way to go about it, but hey it's interesting to see how well an object aligned to the sun for constant exposed area heats up exactly like the theoretical physics says it should.\n",
    "# sample_pass = dete_temp[down_start_temp:down_end_temp, :]\n",
    "# \n",
    "# \n",
    "# #we need a function to fit the shape of a-exp(b/(x-c))\n",
    "# def heat_curve(x, a, b, c, d):\n",
    "# \treturn a * np.exp(b * x + c) + d\n",
    "# \n",
    "# \n",
    "# def minimization(args):\n",
    "# \ta, b, c, d = args[0], args[1], args[2], args[3]\n",
    "# \tarray1 = sample_pass[:, 1]\n",
    "# \tarray2 = heat_curve(sample_pass[:, 0] - sample_pass[0, 0], a, b, c, d)\n",
    "# \tdist = array1 - array2\n",
    "# \treturn sum(dist)\n",
    "# \n",
    "# \n",
    "# # ans = sp.optimize.minimize(minimization,np.asarray([30,sample_pass[0,0]+1e9/1e9,1/1e9]),method='COBYLA',tol=1e-3)\n",
    "# ans = sp.optimize.minimize(\n",
    "# \tminimization, \n",
    "# \tnp.asarray([-1, -1 / 9.94e2, 9.49094e5 + 15.1685, 21.999]), \n",
    "# \tmethod='SLSQP', \n",
    "# \toptions={'ftol': 0.01, 'eps': 0.0001}\n",
    "# \t)\n",
    "# mp.figure(figsize=(10, 3.33))\n",
    "# mp.title('curve fit for spacecraft temp')\n",
    "# mp.plot(sample_pass[:, 0] - sample_pass[0, 0], sample_pass[:, 1])\n",
    "# mp.plot(\n",
    "# \tsample_pass[:, 0] - sample_pass[0, 0],\n",
    "# \theat_curve(sample_pass[:, 0], -1, -1 / 9.94e2, 9.49094e5 + 15.1685, 21.999)\n",
    "# \t)\n",
    "# # #ok, so I'm able to improve the optimization by hand, by looking at the graph, so I'm going to say that the optimize function isn't doing much here.\n",
    "# # \n",
    "# # print(ans)\n",
    "# \n",
    "# mp.figure(figsize=(10, 3.33))\n",
    "# mp.title('error of curve fit for spacecraft temp')\n",
    "# mp.plot(\n",
    "# \tsample_pass[:, 0] - sample_pass[0, 0], \n",
    "# \tsample_pass[:, 1] - heat_curve(sample_pass[:, 0], -1, -1 / 9.94e2, 9.49094e5 + 15.1685, 21.999)\n",
    "# \t)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d2e3f21c1231d881"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# I want some filters, so I'm copying these for a former project of mine, these are exclusively my work, so they fit within the allowed resources. \n",
    "import math as m\n",
    "import numpy as np\n",
    "import typing\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "def fourier_filter(\n",
    "\t\tsignal: typing.Union[np.ndarray, xr.DataArray],\n",
    "\t\tfrequency: float,\n",
    "\t\tcutoff_frequency_low: float = 0,\n",
    "\t\tcutoff_frequency_high: float = 0,\n",
    "\t\ttime_axis: int = 0,\n",
    "\t\tlow_pass: bool = False,\n",
    "\t\thigh_pass: bool = False,\n",
    "\t\tband_pass: bool = False,\n",
    "\t\tband_block: bool = False\n",
    "\t\t) -> typing.Union[np.ndarray, xr.DataArray]:\n",
    "\t\"\"\"Filter a dataset by frequency. This function allows for low_pass,\n",
    "    high_pass, band_pass, or band_block filtering of the data's freqency\n",
    "    representation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : ndarray, :class:`xarray.DataArray`\n",
    "        n-dimensional dataset\n",
    "\n",
    "    frequency : :class:`float`\n",
    "        sample frequency of dataset\n",
    "\n",
    "    cutoff_frequency_low : float, optional\n",
    "        low frequency for cutting fourier transform, used by low_pass, band_pass, band_block. Defaults to 0.\n",
    "\n",
    "    cutoff_frequency_high : float, optional\n",
    "        high frequency for cutting fourier transform, used by low_pass, band_pass, band_block. Defaults to 0.\n",
    "\n",
    "    time_axis : int, optional\n",
    "        the time axis of the data set. Defaults to 0.\n",
    "\n",
    "    low_pass : bool, optional\n",
    "        runs a low_pass filter on the data if set to True. Defaults to False.\n",
    "\n",
    "    high_pass : bool, optional\n",
    "        runs a high_pass filter on the data if set to True. Defaults to False.\n",
    "\n",
    "    band_pass : bool, optional\n",
    "        runs a band_pass filter on the data if set to True. Defaults to False.\n",
    "\n",
    "    band_block : bool, optional\n",
    "        runs a band_block filter on the data if set to True. Defaults to False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    return_signal : ndarray, :class:`xarray.DataArray`\n",
    "        signal with specified filters applied\n",
    "\n",
    "    \"\"\"\n",
    "\tresolution = frequency / len(signal)\n",
    "\tsignal = np.swapaxes(signal, time_axis, 0)\n",
    "\tres_fft = np.fft.fft(signal, axis=0)\n",
    "\tcfl_index = m.floor(cutoff_frequency_low / resolution)\n",
    "\tcfln_index = 1 - cfl_index\n",
    "\tcfh_index = m.ceil(cutoff_frequency_high / resolution)\n",
    "\tcfhn_index = 1 - cfh_index\n",
    "\tif low_pass:\n",
    "\t\tif cfl_index > 1:\n",
    "\t\t\tres_fft[cfl_index:cfln_index] = np.zeros(\n",
    "\t\t\t\tres_fft[cfl_index:cfln_index].shape\n",
    "\t\t\t\t)\n",
    "\t\telse:\n",
    "\t\t\tres_fft[cfl_index:] = np.zeros(res_fft[cfl_index:].shape)\n",
    "\tif high_pass:\n",
    "\t\tres_fft[:cfh_index] = np.zeros(res_fft[:cfh_index].shape)\n",
    "\t\tif cfh_index > 1:\n",
    "\t\t\tres_fft[cfhn_index:] = np.zeros(res_fft[cfhn_index:].shape)\n",
    "\tif band_pass:\n",
    "\t\tres_fft[:cfl_index] = np.zeros(res_fft[:cfl_index].shape)\n",
    "\t\tif cfh_index > 1:\n",
    "\t\t\tres_fft[cfh_index:cfhn_index] = np.zeros(\n",
    "\t\t\t\tres_fft[cfh_index:cfhn_index].shape\n",
    "\t\t\t\t)\n",
    "\t\telse:\n",
    "\t\t\tres_fft[cfh_index:] = np.zeros(res_fft[cfh_index:].shape)\n",
    "\t\tif cfl_index > 1:\n",
    "\t\t\tres_fft[cfln_index:] = np.zeros(res_fft[cfln_index:].shape)\n",
    "\tif band_block:\n",
    "\t\tres_fft[cfl_index:cfh_index] = np.zeros(\n",
    "\t\t\tres_fft[cfl_index:cfh_index].shape\n",
    "\t\t\t)\n",
    "\t\tif cfl_index > 1 and cfh_index > 1:\n",
    "\t\t\tres_fft[cfhn_index:cfln_index] = np.zeros(\n",
    "\t\t\t\tres_fft[cfhn_index:cfln_index].shape\n",
    "\t\t\t\t)\n",
    "\t\telif cfh_index > 1:\n",
    "\t\t\tres_fft[cfhn_index:] = np.zeros(res_fft[cfhn_index:].shape)\n",
    "\tresult = np.fft.ifft(res_fft, axis=0)\n",
    "\tresult = np.real(result)\n",
    "\tresult = np.swapaxes(result, time_axis, 0)\n",
    "\tif type(signal) == xr.DataArray:\n",
    "\t\txr_result = signal.copy()\n",
    "\t\txr_result.data = result\n",
    "\t\tresult = xr_result\n",
    "\treturn result\n",
    "\n",
    "\n",
    "def fourier_low_pass(\n",
    "\t\tsignal: typing.Union[np.ndarray, xr.DataArray],\n",
    "\t\tfrequency: float,\n",
    "\t\tcutoff_frequency_low: float,\n",
    "\t\ttime_axis: int = 0\n",
    "\t\t) -> typing.Union[np.ndarray, xr.DataArray]:\n",
    "\t\"\"\"Filter a dataset by frequency. This function allowes for low_pass\n",
    "    filtering of the data's freqency representation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : ndarray, :class:`xarray.DataArray`\n",
    "        n-dimensional dataset\n",
    "\n",
    "    frequency : :class:`float`\n",
    "        sample frequency of dataset\n",
    "\n",
    "    cutoff_frequency_low : :class:`float`\n",
    "        low frequency for cutting fourier transform\n",
    "\n",
    "    time_axis : int, optional\n",
    "        the time axis of the data set. Defaults to 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    return_signal : ndarray, :class:`xarray.DataArray`\n",
    "        signal with specified filters applied\n",
    "    \"\"\"\n",
    "\treturn fourier_filter(\n",
    "\t\tsignal,\n",
    "\t\tfrequency,\n",
    "\t\tcutoff_frequency_low=cutoff_frequency_low,\n",
    "\t\ttime_axis=time_axis,\n",
    "\t\tlow_pass=True\n",
    "\t\t)\n",
    "\n",
    "\n",
    "def fourier_high_pass(\n",
    "\t\tsignal: typing.Union[np.ndarray, xr.DataArray],\n",
    "\t\tfrequency: float,\n",
    "\t\tcutoff_frequency_high: float,\n",
    "\t\ttime_axis: int = 0\n",
    "\t\t) -> typing.Union[np.ndarray, xr.DataArray]:\n",
    "\t\"\"\"Filter a dataset by frequency. This function allowes for high_pass\n",
    "    filtering of the data's freqency representation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : ndarray, :class:`xarray.DataArray`\n",
    "        n-dimensional dataset\n",
    "\n",
    "    frequency : :class:`float`\n",
    "        sample frequency of dataset\n",
    "\n",
    "    cutoff_frequency_high : :class:`float`\n",
    "        high frequency for cutting fourier transform\n",
    "\n",
    "    time_axis : int, optional\n",
    "        the time axis of the data set. Defaults to 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    return_signal : ndarray, :class:`xarray.DataArray`\n",
    "        signal with specified filters applied\n",
    "    \"\"\"\n",
    "\treturn fourier_filter(\n",
    "\t\tsignal,\n",
    "\t\tfrequency,\n",
    "\t\tcutoff_frequency_high=cutoff_frequency_high,\n",
    "\t\ttime_axis=time_axis,\n",
    "\t\thigh_pass=True\n",
    "\t\t)\n",
    "\n",
    "\n",
    "def fourier_band_pass(\n",
    "\t\tsignal: typing.Union[np.ndarray, xr.DataArray],\n",
    "\t\tfrequency: float,\n",
    "\t\tcutoff_frequency_low: float,\n",
    "\t\tcutoff_frequency_high: float,\n",
    "\t\ttime_axis: int = 0\n",
    "\t\t) -> typing.Union[np.ndarray, xr.DataArray]:\n",
    "\t\"\"\"Filter a dataset by frequency. This function allowes for band_pass\n",
    "    filtering of the data's freqency representation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : ndarray, :class:`xarray.DataArray`\n",
    "        n-dimensional dataset\n",
    "\n",
    "    frequency : :class:`float`\n",
    "        sample frequency of dataset\n",
    "\n",
    "    cutoff_frequency_low : :class:`float`\n",
    "        low frequency for cutting fourier transform\n",
    "\n",
    "    cutoff_frequency_high : :class:`float`\n",
    "        high frequency for cutting fourier transform\n",
    "\n",
    "    time_axis : int, optional\n",
    "        the time axis of the data set. Defaults to 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    return_signal : ndarray, :class:`xarray.DataArray`\n",
    "        signal with specified filters applied\n",
    "    \"\"\"\n",
    "\treturn fourier_filter(\n",
    "\t\tsignal,\n",
    "\t\tfrequency,\n",
    "\t\tcutoff_frequency_low=cutoff_frequency_low,\n",
    "\t\tcutoff_frequency_high=cutoff_frequency_high,\n",
    "\t\ttime_axis=time_axis,\n",
    "\t\tband_pass=True\n",
    "\t\t)\n",
    "\n",
    "\n",
    "def fourier_band_block(\n",
    "\t\tsignal: typing.Union[np.ndarray, xr.DataArray],\n",
    "\t\tfrequency: float,\n",
    "\t\tcutoff_frequency_low: float,\n",
    "\t\tcutoff_frequency_high: float,\n",
    "\t\ttime_axis: int = 0\n",
    "\t\t) -> typing.Union[np.ndarray, xr.DataArray]:\n",
    "\t\"\"\"Filter a dataset by frequency. This function allowes for band_block\n",
    "    filtering of the data's freqency representation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : ndarray, :class:`xarray.DataArray`\n",
    "        n-dimensional dataset\n",
    "\n",
    "    frequency : :class:`float`\n",
    "        sample frequency of dataset\n",
    "\n",
    "    cutoff_frequency_low : :class:`float`\n",
    "        low frequency for cutting fourier transform\n",
    "\n",
    "    cutoff_frequency_high : :class:`float`\n",
    "        high frequency for cutting fourier transform\n",
    "\n",
    "    time_axis : int, optional\n",
    "        the time axis of the data set. Defaults to 0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    return_signal : ndarray, :class:`xarray.DataArray`\n",
    "        signal with specified filters applied\n",
    "    \"\"\"\n",
    "\treturn fourier_filter(\n",
    "\t\tsignal,\n",
    "\t\tfrequency,\n",
    "\t\tcutoff_frequency_low=cutoff_frequency_low,\n",
    "\t\tcutoff_frequency_high=cutoff_frequency_high,\n",
    "\t\ttime_axis=time_axis,\n",
    "\t\tband_block=True\n",
    "\t\t)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aeba81f74d5f5684"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Temp correction\n",
    "fig, axs = mp.subplots(3, 1, figsize=(10, 15))\n",
    "axs[1].title.set_text('darks')\n",
    "axs[1].plot(dark_raw[:, 0] - dark_raw[0, 0], dark_raw[:, 2])\n",
    "\n",
    "#darks using a linear fit of temperature\n",
    "def minimization(args):\n",
    "\ta, b = args[0], args[1]\n",
    "\tarray1 = dark_raw[:, 2]\n",
    "\tarray2 = (dark_temp[:, 1] - a) * b\n",
    "\tdist = array1 - array2\n",
    "\treturn sum(dist ** 2)\n",
    "\n",
    "temp_fit = sp.optimize.minimize(\n",
    "\tminimization, np.asarray([-18, 800]), method='SLSQP'\n",
    "\t)\n",
    "print(temp_fit.x)\n",
    "axs[1].plot(\n",
    "\tdark_temp[:, 0] - dark_temp[0, 0],\n",
    "\t(dark_temp[:, 1] - temp_fit.x[0]) * temp_fit.x[1]\n",
    "\t)\n",
    "\n",
    "#show the trend using a low pass filter\n",
    "axs[1].plot(dark_raw[:, 0] - dark_raw[0, 0], fourier_low_pass(dark_raw[:, 2], 1, 1 / 100))\n",
    "\n",
    "#darks the handout way\n",
    "dark_integrationTime = 1.0\n",
    "dark_counts_handout = dark_raw[:, 2]  #number of darculas (dark counts)\n",
    "detectorTemp = dark_temp[:, 1]\n",
    "tempCorrFactor = 0.0061628  # [counts/degC]\n",
    "dark_count_rate = dark_counts_handout / dark_integrationTime\n",
    "dark_count_rate_corr = dark_count_rate * (\n",
    "\t\t1.0 + tempCorrFactor * (20.0 - detectorTemp))\n",
    "median_dark_count_rate1 = np.median(dark_count_rate_corr)\n",
    "axs[1].plot(\n",
    "\t[0, dark_temp[-1, 0] - dark_temp[0, 0]],\n",
    "\t[median_dark_count_rate1, median_dark_count_rate1]\n",
    "\t)\n",
    "\n",
    "#ez mode median dark count rate using np.median()\n",
    "median_dark_count_rate2 = np.median(dark_raw[:, 2])\n",
    "axs[1].plot(\n",
    "\t[0, dark_raw[-1, 0] - dark_raw[0, 0]],\n",
    "\t[median_dark_count_rate2, median_dark_count_rate2]\n",
    "\t)\n",
    "\n",
    "mean_dark_count_rate2 = np.mean(dark_raw[:, 2])\n",
    "axs[1].plot(\n",
    "\t[0, dark_raw[-1, 0] - dark_raw[0, 0]],\n",
    "\t[mean_dark_count_rate2, mean_dark_count_rate2]\n",
    "\t)\n",
    "\n",
    "axs[1].legend(\n",
    "\t['darks', 'temperature scaled to match trend', '0.01Hz low pass fourier',\n",
    "\t 'median dark count rate handout', 'median dark count rate numpy', 'mean dark count rate numpy']\n",
    "\t)\n",
    "\n",
    "axs[2].title.set_text('upscan')\n",
    "axs[2].plot(\n",
    "\tup_raw[:, 0] - up_raw[0, 0], up_raw[:, 2]\n",
    "\t)\n",
    "axs[2].plot(\n",
    "\tup_temp[:, 0] - up_temp[0, 0],\n",
    "\t(up_temp[:, 1] - temp_fit.x[0]) * temp_fit.x[1]\n",
    "\t)\n",
    "\n",
    "axs[0].title.set_text('downscan')\n",
    "axs[0].plot(down_raw[:, 0] - down_raw[0, 0], down_raw[:, 2])\n",
    "axs[0].plot(\n",
    "\tup_temp[:, 0] - up_temp[0, 0],\n",
    "\t(up_temp[:, 1] - temp_fit.x[0]) * temp_fit.x[1]\n",
    "\t)\n",
    "\n",
    "# maybe use scikit-image.transform.resize to get the heat curve in the same length as the data bins, this is a handy tool for rescaling arrays, it defaults to linear interpolation which is close enough, but could be expanded up to 5th order if needed.\n",
    "up_temp_counts = ski.transform.resize(\n",
    "\t(up_temp[:, 1] - temp_fit.x[0]) * temp_fit.x[1] * up_exposure,\n",
    "\t(len(up_raw),),\n",
    "\tmode='edge'\n",
    "\t)\n",
    "\n",
    "down_temp_counts = ski.transform.resize(\n",
    "\t(down_temp[:, 1] - temp_fit.x[0]) * temp_fit.x[1] * down_exposure,\n",
    "\t(len(down_raw),),\n",
    "\tmode='edge'\n",
    "\t)\n",
    "\n",
    "dark_temp_counts = ski.transform.resize(\n",
    "\t(dark_temp[:, 1] - temp_fit.x[0]) * temp_fit.x[1] * dark_exposure,\n",
    "\t(len(dark_raw),),\n",
    "\tmode='edge'\n",
    "\t)\n",
    "\n",
    "#TODO the count rate correction needs to be applied in addition to the dark correction.\n",
    "# tempCorrFactor = 0.0061628  # [counts/degC]\n",
    "# count_rate_corr = count_rate * (1.0 + tempCorrFactor * (20.0 - detectorTemp))\n",
    "# this should be done after(?) the dark temp subtraction.\n",
    "# my read is that this corrects for differential sensor sensitivity, which would be the photon counts other than the thermal effects accounted for using \"darks\" so it should be calculated based on the post-dark removal value. This behavior is likely wavelenth dependent as well, but I don't have access to any characterization data, so I have to use the single value for tempCorrFactor I was given.\n",
    "\n",
    "down_corr_counts = (down_raw[:, 2] - down_temp_counts) * (tempCorrFactor * (20 - ski.transform.resize(down_temp[:, 1], (len(down_raw),), mode='edge'))) # we are only taking the diffence value here, and will remove it later\n",
    "up_corr_counts = (up_raw[:, 2] - up_temp_counts) * (tempCorrFactor * (20 - ski.transform.resize(up_temp[:, 1], (len(up_raw),), mode='edge'))) # we are only taking the diffence value here, and will remove it later\n",
    "\n",
    "#double check everything\n",
    "fig, axs = mp.subplots(3, 1, figsize=(10, 15))\n",
    "axs[1].title.set_text('darks')\n",
    "axs[1].plot(dark_raw[:, 0] - dark_raw[0, 0], dark_raw[:, 2] - dark_temp_counts)\n",
    "axs[1].plot(dark_raw[:, 0] - dark_raw[0, 0], fourier_low_pass(dark_raw[:, 2] - dark_temp_counts, 1, 1 / 100))\n",
    "median_dark_count_rate2 = np.median(dark_raw[:, 2] - dark_temp_counts)\n",
    "axs[1].plot(\n",
    "\t[0, dark_raw[-1, 0] - dark_raw[0, 0]],\n",
    "\t[median_dark_count_rate2, median_dark_count_rate2]\n",
    "\t)\n",
    "mean_dark_count_rate2 = np.mean(dark_raw[:, 2] - dark_temp_counts)\n",
    "axs[1].plot(\n",
    "\t[0, dark_raw[-1, 0] - dark_raw[0, 0]],\n",
    "\t[mean_dark_count_rate2, mean_dark_count_rate2]\n",
    "\t)\n",
    "axs[1].legend(\n",
    "\t['corrected darks', \n",
    "\t '0.01Hz low pass fourier', \n",
    "\t 'median dark count rate numpy', \n",
    "\t 'mean dark count rate numpy']\n",
    "\t)\n",
    "print('median dark, after adjustment: ' + str(np.median(dark_raw[:, 2] - dark_temp_counts)))\n",
    "print('mean dark, after adjustment: ' + str(np.mean(dark_raw[:, 2] - dark_temp_counts)))\n",
    "axs[2].title.set_text('upscan')\n",
    "axs[2].plot(up_raw[:, 0] - up_raw[0, 0], up_raw[:, 2] - up_temp_counts)\n",
    "axs[0].title.set_text('downscan')\n",
    "axs[0].plot(down_raw[:, 0] - down_raw[0, 0], down_raw[:, 2] - down_temp_counts)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8893e45c38d31ae6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#wavelengths\n",
    "offset = 239532.38\n",
    "stepSize = 2.4237772022101214E-6  # [rad/step]\n",
    "d = 277.77777777777777  # [nm]\n",
    "phiGInRads = 0.08503244115716374  # [rad]\n",
    "#gratingPosition comes from inst_tele[:,1]\n",
    "gratingPosition = inst_tele[:, 1]\n",
    "ang1 = (offset - gratingPosition) * stepSize  # [rad]\n",
    "wavelength = 2 * d * np.sin(ang1) * np.cos(phiGInRads / 2.0)  # [nm]\n",
    "#I know that the angular dispersion from a diffraction grating is not linear with wavelength, and that this equation is using a linear assumption, I'm not going to attempt (yet) to rederive this for a hardware configuration I know almost nothing about, but I want to. \n",
    "down_wave_raw = wavelength[down_start:down_end]\n",
    "up_wave_raw = wavelength[up_start:up_end]\n",
    "\n",
    "#I need to do the doppler shift array as well, this is more time dependant (spacecraft velocity) and while \"can be ignored for this excercise\" is written in the lore, I don't think I'm going to ignore it. it should be relatively straightforard to do with the tools and data at hand, so let's give it half an hour to find out.\n",
    "\n",
    "down_start_dopp = np.where(dist_dopp[:, 0] >= down_start_time)[0][0]\n",
    "down_end_dopp = np.where(dist_dopp[:, 0] >= down_end_time)[0][0]\n",
    "print(\"down samples: \" + str(down_end_dopp - down_start_dopp))\n",
    "dark_start_dopp = np.where(dist_dopp[:, 0] >= dark_start_time)[0][0]\n",
    "dark_end_dopp = np.where(dist_dopp[:, 0] >= dark_end_time)[0][0]\n",
    "print(\"dark samples: \" + str(dark_end_dopp - dark_start_dopp))\n",
    "up_start_dopp = np.where(dist_dopp[:, 0] >= up_start_time)[0][0]\n",
    "up_end_dopp = np.where(dist_dopp[:, 0] >= up_end_time)[0][0]\n",
    "print(\"up samples: \" + str(up_end_dopp - up_start_dopp))\n",
    "\n",
    "down_dist_dopp = dist_dopp[down_start_dopp:down_end_dopp, :]\n",
    "dark_dist_dopp = dist_dopp[dark_start_dopp:dark_end_dopp, :]\n",
    "up_dist_dopp = dist_dopp[up_start_dopp:up_end_dopp, :]\n",
    "\n",
    "mp.figure(figsize=(10,5))\n",
    "mp.title('doppler shifts overall')\n",
    "mp.plot(dist_dopp[:,0], dist_dopp[:,2])\n",
    "mp.plot(down_dist_dopp[:, 0], down_dist_dopp[:, 2])\n",
    "mp.plot(dark_dist_dopp[:, 0], dark_dist_dopp[:, 2])\n",
    "mp.plot(up_dist_dopp[:, 0], up_dist_dopp[:, 2])\n",
    "mp.legend(['full doppler shift dataset','downscan doppler','darks doppler','upscan dopppler'])\n",
    "\n",
    "#we don't have a lot of samples, so we're going to use ski.transform.resize again, I do like this functions for giving exactly what I need a lot of the time.\n",
    "up_dopp_shifts = ski.transform.resize(\n",
    "\tup_dist_dopp[:, 2],\n",
    "\t(len(up_raw),),\n",
    "\tmode='edge'\n",
    "\t)\n",
    "dark_dopp_shifts = ski.transform.resize(\n",
    "\tdark_dist_dopp[:, 2],\n",
    "\t(len(dark_raw),),\n",
    "\tmode='edge'\n",
    "\t)\n",
    "down_dopp_shifts = ski.transform.resize(\n",
    "\tdown_dist_dopp[:, 2],\n",
    "\t(len(down_raw),),\n",
    "\tmode='edge'\n",
    "\t)\n",
    "\n",
    "mp.figure(figsize=(10,5))\n",
    "mp.title('comparison of downscan, dark, and upscan doppler shifts' )\n",
    "mp.plot(down_raw[:, 0] - down_raw[0,0], down_dopp_shifts)\n",
    "mp.plot(dark_raw[:, 0] - dark_raw[0,0], dark_dopp_shifts)\n",
    "mp.plot(up_raw[:, 0] - up_raw[0,0], up_dopp_shifts)\n",
    "mp.legend(['downscan doppler','darks doppler','upscan dopppler'])\n",
    "\n",
    "#adjust the raw wave for doppler\n",
    "down_wave_dopp = down_wave_raw * down_dopp_shifts\n",
    "up_wave_dopp = up_wave_raw * up_dopp_shifts\n",
    "\n",
    "#grating shift offest in terms of spectrum.\n",
    "print('spectral peak wavelength from dopper corrected data')\n",
    "print(\n",
    "\t'reference: ' \n",
    "\t+ str(refe_spec[np.where(refe_spec[:, 1] == np.max(refe_spec[:, 1])), 0][0][0]) \n",
    "\t+ 'nm'\n",
    "\t)\n",
    "print(\n",
    "\t'up scan: '\n",
    "\t+ str(up_wave_dopp[np.where(up_raw[:, 2] == np.max(up_raw[:, 2]))][0])\n",
    "\t+ 'nm'\n",
    "\t)\n",
    "print(\n",
    "\t'down scan: '\n",
    "\t+ str(down_wave_dopp[np.where(down_raw[:, 2] == np.max(down_raw[:, 2]))][0]) \n",
    "\t+ 'nm'\n",
    "\t)\n",
    "#this naive alignment technique has a potential error of Â± stepsize/2\n",
    "# in this case 0.006339413449239828 nm\n",
    "# this error could be automatically removed by using maximum of a polyfit,\n",
    "# which I'll do if every higher proirity task for this is done.\n",
    "reference_peak = refe_spec[np.where(refe_spec[:, 1] == np.max(refe_spec[:, 1])), 0][0][0]\n",
    "up_wave_peak = up_wave_dopp[np.where(up_raw[:, 2] == np.max(up_raw[:, 2]))][0]\n",
    "down_wave_peak = down_wave_dopp[np.where(down_raw[:, 2] == np.max(down_raw[:, 2]))][0]\n",
    "\n",
    "up_wave_offset = reference_peak - up_wave_peak\n",
    "down_wave_offset = reference_peak - down_wave_peak\n",
    "print('downscan wavelength offset'+str(down_wave_offset))\n",
    "print('upscan wavelength offset'+str(up_wave_offset))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68917090e339d2b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#create calibrated datasets for the observations here\n",
    "#remove thermal dark, and adjust for sensitivity changes related to sensor temperature. \n",
    "down_counts_real = down_raw[:, 2] - down_temp_counts + down_corr_counts\n",
    "dark_counts_real = dark_raw[:, 2] - dark_temp_counts\n",
    "up_counts_real = up_raw[:, 2] - up_temp_counts + up_corr_counts\n",
    "up_waves = up_wave_dopp+up_wave_offset\n",
    "down_waves = down_wave_dopp+down_wave_offset\n",
    "\n",
    "up_real =np.rot90(np.asarray([up_raw[:, 0], up_waves, up_counts_real]))\n",
    "down_real =np.rot90(np.asarray([down_raw[:, 0], down_waves, down_counts_real]))\n",
    "\n",
    "fig, axs = mp.subplots(2, 1, figsize=(10, 10))\n",
    "axs[0].title.set_text('comparing alignment of corrected data')\n",
    "axs[0].plot(refe_spec[1850:2000, 0], refe_spec[1850:2000, 1] * np.max(up_real[:, 2]) / np.max(refe_spec[:, 1]))\n",
    "axs[0].plot(down_real[1450:1550, 1], down_real[1450:1550, 2])\n",
    "axs[0].plot(up_real[1150:1250, 1], up_real[1150:1250, 2])\n",
    "axs[0].legend(\n",
    "\t['reference spec, scaled to match',\n",
    "\t 'down_correct data',\n",
    "\t 'up_correct data',]\n",
    "\t)\n",
    "#there are expected alignment errors less than 0.00633nm due to width of the wavelength bins, so I'm going to eyeball a correction to the two data lines.\n",
    "axs[1].title.set_text('improved alignment of corrected data\\nadjusted for errors left after naive alignment of max values')\n",
    "axs[1].plot(refe_spec[1850:2000, 0], refe_spec[1850:2000, 1] * np.max(up_real[:, 2]) / np.max(refe_spec[:, 1]))\n",
    "axs[1].plot(down_real[1450:1550, 1] - 0.005, down_real[1450:1550, 2])\n",
    "axs[1].plot(up_real[1150:1250, 1] - 0.001, up_real[1150:1250, 2])\n",
    "\n",
    "axs[1].legend(\n",
    "\t['reference spec, scaled to match',\n",
    "\t 'down_correct data',\n",
    "\t 'up_correct data',]\n",
    "\t)\n",
    "\n",
    "#redo corrected data with manual adjustments of 0.001nm and 0.005nm for up and down\n",
    "#the correction was done with a matched pair of laser corrected eyeballs calibrated to ISO 12233.\n",
    "#also repacking the data nicely for the next set of steps\n",
    "down_real =np.transpose(np.asarray([down_raw[:, 0], down_waves - 0.005, down_counts_real]))\n",
    "up_real =np.transpose(np.asarray([up_raw[:, 0], up_waves - 0.001, up_counts_real]))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d12d559fbba155ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#scale the data to photons/(meter^2 * seconds)\n",
    "#from:\n",
    "# apertureArea = .01 / (1E2 * 1E2)  # [m^2] (aperature area from cm^2 to m^2)\n",
    "# photonsPerSecondPerM2 = (count_rate_corr - median_dark_count_rate) / apertureArea  [photons/sec/m^2/nm]\n",
    "# h = 6.62606957E-34  # [J*s]\n",
    "# c = 299792458.0  # [m/s]\n",
    "# energyPerPhoton = h * c / wavelengthInMeters  # [J]\n",
    "# wattsPerM2 = photonsPerSecondPerM2 * energyPerPhoton  # [watts/m^2/nm]\n",
    "# wattsPerM2_1AU = wattsPerM2 / sunObserverDistanceCorrection  # [watts/m^2/nm]\n",
    "aperature_scale = 1e6\n",
    "h = 6.62606957E-34  # [J*s] # this is using an old value of the Planck constant from NIST CODATA 2010 the value has since been refined to 6.62607015e-34 in NIST CODATA 2018 and pinned to the 2018 value as exact decimal precision in SI 9th edition from 2019. ref (https://www.bipm.org/documents/20126/41483022/SI-Brochure-9.pdf) also, thanks for reading the code comments, I hope you enjoyed the funny ones, and no, I won't tell you which ones were meant to be funny.\n",
    "h = 6.62607015e-34 # [J*s]\n",
    "c = 299792458.0  # [m/s]\n",
    "down_photon_energy = c*h/(down_real[:,1]/1e9) # the 1e9 is to convert from nm to m\n",
    "up_photon_energy = c*h/(up_real[:,1]/1e9) # the 1e9 is to convert from nm to m\n",
    "\n",
    "down_energy_measured = down_real[:, 2]*aperature_scale*down_photon_energy/down_exposure\n",
    "up_energy_measured = up_real[:, 2]*aperature_scale*up_photon_energy/up_exposure\n",
    "\n",
    "# adjust for AU distance from sun.\n",
    "# and again, to scale the dataset to our sensor cadence ski.transform.resize is just the thing\n",
    "up_dist_shifts = ski.transform.resize(\n",
    "\tup_dist_dopp[:, 1],\n",
    "\t(len(up_raw),),\n",
    "\tmode='edge'\n",
    "\t)\n",
    "dark_dist_shifts = ski.transform.resize(\n",
    "\tdark_dist_dopp[:, 1],\n",
    "\t(len(dark_raw),),\n",
    "\tmode='edge'\n",
    "\t)\n",
    "down_dist_shifts = ski.transform.resize(\n",
    "\tdown_dist_dopp[:, 1],\n",
    "\t(len(down_raw),),\n",
    "\tmode='edge'\n",
    "\t)\n",
    "\n",
    "down_energy_1au = down_energy_measured/down_dist_shifts\n",
    "up_energy_1au = up_energy_measured/up_dist_shifts\n",
    "\n",
    "# a glance in the dirdection of our data to see if it's in line with expectations.\n",
    "fig, axs = mp.subplots(2,1,figsize=(10,10))\n",
    "axs[0].plot(refe_spec[:, 0], refe_spec[:, 1])\n",
    "axs[0].plot(down_real[:, 1], down_energy_1au)\n",
    "axs[0].plot(up_real[:,1], up_energy_1au)\n",
    "axs[0].title.set_text('comparing result to reference values')\n",
    "axs[0].legend(\n",
    "\t['reference',\n",
    "\t 'down',\n",
    "\t 'up',]\n",
    "\t)\n",
    "\n",
    "axs[1].title.set_text('comparing result to reference values near peak')\n",
    "axs[1].plot(refe_spec[1850:2000, 0], refe_spec[1850:2000, 1])\n",
    "axs[1].plot(down_real[1000:1100, 1], down_energy_measured[1000:1100])\n",
    "axs[1].plot(up_real[1250:1350, 1], up_energy_measured[1250:1350])\n",
    "axs[1].legend(\n",
    "\t['reference',\n",
    "\t 'down',\n",
    "\t 'up',]\n",
    "\t)\n",
    "\n",
    "#and a final repack before our last set of graphs.\n",
    "down_result = np.transpose(np.asarray([down_real[:,0], down_real[:,1],down_energy_1au]))\n",
    "up_result = np.transpose(np.asarray([up_real[:,0], up_real[:,1],up_energy_1au]))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60dc20fb3559742b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.savetxt('data_external/Spectral_Instensities_from_Downscan.txt', down_result, delimiter=',', header='Time(s),Wavelength(nm),Intensity(W/m^2)')\n",
    "np.savetxt('data_external/Spectral_Instensities_from_Upscan.txt', up_result, delimiter=',', header='Time(s),Wavelength(nm),Intensity(W/m^2)')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62364bef93c1d304"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4e1c4df87f316635"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1301398ff18e1eac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "536fb2a462542bbf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9513f91228a5d8ea"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cba345029d59ae51"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bb57d9f1c51bb5b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1496d79b0b1bd371"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8131db414d1f7a05"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
